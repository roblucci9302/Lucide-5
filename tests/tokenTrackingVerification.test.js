/**
 * Token Tracking Verification Test Suite
 *
 * Tests the token tracking system for:
 * 1. Usage per request accuracy
 * 2. Pre-send estimation precision
 * 3. Session accumulation exactness
 * 4. Provider log comparison
 *
 * Run with: node tests/tokenTrackingVerification.test.js
 */

// Simple assertion helper
function assert(condition, message) {
    if (!condition) {
        throw new Error(`Assertion failed: ${message}`);
    }
}

function assertEqual(actual, expected, message) {
    if (actual !== expected) {
        throw new Error(`${message}: expected ${expected}, got ${actual}`);
    }
}

function assertCloseTo(actual, expected, delta, message) {
    if (Math.abs(actual - expected) > delta) {
        throw new Error(`${message}: expected ${expected} Â± ${delta}, got ${actual}`);
    }
}

function assertInRange(actual, min, max, message) {
    if (actual < min || actual > max) {
        throw new Error(`${message}: expected ${min}-${max}, got ${actual}`);
    }
}

// Test runner
const results = {
    passed: 0,
    failed: 0,
    tests: []
};

async function runTest(name, testFn) {
    try {
        await testFn();
        results.passed++;
        results.tests.push({ name, status: 'PASS' });
        console.log(`  âœ… ${name}`);
    } catch (error) {
        results.failed++;
        results.tests.push({ name, status: 'FAIL', error: error.message });
        console.log(`  âŒ ${name}`);
        console.log(`     Error: ${error.message}`);
    }
}

function describe(name, fn) {
    console.log(`\n${name}`);
    console.log('â”€'.repeat(60));
    fn();
}

// Mock electron-store before requiring tokenTrackingService
class MockStore {
    constructor(options = {}) {
        this.data = options.defaults ? { ...options.defaults } : {};
    }
    get(key) {
        return this.data[key];
    }
    set(key, value) {
        this.data[key] = value;
    }
    clear() {
        this.data = {};
    }
}

// Override require for electron-store
const Module = require('module');
const originalRequire = Module.prototype.require;

Module.prototype.require = function(id) {
    if (id === 'electron-store') {
        return MockStore;
    }
    return originalRequire.apply(this, arguments);
};

// Now require the services
const tokenTrackingService = require('../src/features/common/services/tokenTrackingService');
const tokenUtils = require('../src/features/common/utils/tokenUtils');

// Test Results Summary
const testResults = {
    usagePerRequest: [],
    estimation: [],
    accumulation: [],
    providerComparison: []
};

// ==========================================================
// MAIN TEST RUNNER
// ==========================================================
async function runAllTests() {
    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
    console.log('â•‘     TOKEN TRACKING VERIFICATION TEST SUITE                   â•‘');
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    // ==========================================================
    // SECTION 1: USAGE PER REQUEST ACCURACY
    // ==========================================================
    describe('ðŸ“Š 1. USAGE PER REQUEST ACCURACY', () => {});

    console.log('\n  1.1 OpenAI Response Extraction');
    tokenTrackingService.resetStats();

    await runTest('OpenAI standard response with raw.usage', () => {
        const response = {
            raw: {
                usage: {
                    prompt_tokens: 150,
                    completion_tokens: 250,
                    total_tokens: 400
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('openai', response);
        assertEqual(result.inputTokens, 150, 'Input tokens');
        assertEqual(result.outputTokens, 250, 'Output tokens');
        assertEqual(result.totalTokens, 400, 'Total tokens');
        assert(!result.estimated, 'Should not be estimated');
        testResults.usagePerRequest.push({ test: 'OpenAI raw.usage', passed: true });
    });

    await runTest('OpenAI response with top-level usage', () => {
        const response = {
            usage: {
                prompt_tokens: 100,
                completion_tokens: 200,
                total_tokens: 300
            }
        };
        const result = tokenTrackingService.extractTokenUsage('openai', response);
        assertEqual(result.inputTokens, 100, 'Input tokens');
        assertEqual(result.outputTokens, 200, 'Output tokens');
        assertEqual(result.totalTokens, 300, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'OpenAI top-level usage', passed: true });
    });

    await runTest('OpenAI Lucide (Portkey) response', () => {
        const response = {
            raw: {
                usage: {
                    prompt_tokens: 500,
                    completion_tokens: 1000,
                    total_tokens: 1500
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('openai-lucide', response);
        assertEqual(result.inputTokens, 500, 'Input tokens');
        assertEqual(result.outputTokens, 1000, 'Output tokens');
        assertEqual(result.totalTokens, 1500, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'OpenAI Lucide', passed: true });
    });

    await runTest('Large token counts (GPT-4 context)', () => {
        const response = {
            raw: {
                usage: {
                    prompt_tokens: 8000,
                    completion_tokens: 4000,
                    total_tokens: 12000
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('openai', response);
        assertEqual(result.inputTokens, 8000, 'Input tokens');
        assertEqual(result.outputTokens, 4000, 'Output tokens');
        assertEqual(result.totalTokens, 12000, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Large token counts', passed: true });
    });

    console.log('\n  1.2 Anthropic Response Extraction');

    await runTest('Anthropic standard response with raw.usage', () => {
        const response = {
            raw: {
                usage: {
                    input_tokens: 200,
                    output_tokens: 300
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('anthropic', response);
        assertEqual(result.inputTokens, 200, 'Input tokens');
        assertEqual(result.outputTokens, 300, 'Output tokens');
        assertEqual(result.totalTokens, 500, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Anthropic raw.usage', passed: true });
    });

    await runTest('Claude alias provider', () => {
        const response = {
            raw: {
                usage: {
                    input_tokens: 1000,
                    output_tokens: 500
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('claude', response);
        assertEqual(result.inputTokens, 1000, 'Input tokens');
        assertEqual(result.outputTokens, 500, 'Output tokens');
        assertEqual(result.totalTokens, 1500, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Claude alias', passed: true });
    });

    await runTest('Claude 3 Opus large response (50K+ tokens)', () => {
        const response = {
            raw: {
                usage: {
                    input_tokens: 50000,
                    output_tokens: 4096
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('anthropic', response);
        assertEqual(result.inputTokens, 50000, 'Input tokens');
        assertEqual(result.outputTokens, 4096, 'Output tokens');
        assertEqual(result.totalTokens, 54096, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Claude 3 Opus large', passed: true });
    });

    console.log('\n  1.3 Gemini Response Extraction');

    await runTest('Gemini Pro response with usageMetadata', () => {
        const response = {
            usageMetadata: {
                promptTokenCount: 100,
                candidatesTokenCount: 200,
                totalTokenCount: 300
            }
        };
        const result = tokenTrackingService.extractTokenUsage('gemini', response);
        assertEqual(result.inputTokens, 100, 'Input tokens');
        assertEqual(result.outputTokens, 200, 'Output tokens');
        assertEqual(result.totalTokens, 300, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Gemini Pro', passed: true });
    });

    await runTest('Google alias provider with raw.usageMetadata', () => {
        const response = {
            raw: {
                usageMetadata: {
                    promptTokenCount: 500,
                    candidatesTokenCount: 1000,
                    totalTokenCount: 1500
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('google', response);
        assertEqual(result.inputTokens, 500, 'Input tokens');
        assertEqual(result.outputTokens, 1000, 'Output tokens');
        assertEqual(result.totalTokens, 1500, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Google alias', passed: true });
    });

    await runTest('Gemini 1.5 Pro large context (100K+ tokens)', () => {
        const response = {
            usageMetadata: {
                promptTokenCount: 100000,
                candidatesTokenCount: 8000,
                totalTokenCount: 108000
            }
        };
        const result = tokenTrackingService.extractTokenUsage('gemini', response);
        assertEqual(result.inputTokens, 100000, 'Input tokens');
        assertEqual(result.outputTokens, 8000, 'Output tokens');
        assertEqual(result.totalTokens, 108000, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Gemini 1.5 Pro large', passed: true });
    });

    console.log('\n  1.4 Ollama (Local Model) Handling');

    await runTest('Ollama returns zero tokens (local model)', () => {
        const result = tokenTrackingService.extractTokenUsage('ollama', {});
        assertEqual(result.inputTokens, 0, 'Input tokens');
        assertEqual(result.outputTokens, 0, 'Output tokens');
        assertEqual(result.totalTokens, 0, 'Total tokens');
        assert(result.local === true, 'Should be marked as local');
        testResults.usagePerRequest.push({ test: 'Ollama local', passed: true });
    });

    console.log('\n  1.5 Edge Cases and Error Handling');

    await runTest('Handle missing usage data gracefully', () => {
        const result = tokenTrackingService.extractTokenUsage('openai', {});
        assertEqual(result.inputTokens, 0, 'Input tokens');
        assertEqual(result.outputTokens, 0, 'Output tokens');
        testResults.usagePerRequest.push({ test: 'Missing usage data', passed: true });
    });

    await runTest('Handle null response', () => {
        const result = tokenTrackingService.extractTokenUsage('openai', null);
        assertEqual(result.inputTokens, 0, 'Input tokens');
        assertEqual(result.outputTokens, 0, 'Output tokens');
        testResults.usagePerRequest.push({ test: 'Null response', passed: true });
    });

    await runTest('Handle unknown provider', () => {
        const result = tokenTrackingService.extractTokenUsage('unknown-provider', {});
        assertEqual(result.error, 'Unknown provider', 'Error message');
        testResults.usagePerRequest.push({ test: 'Unknown provider', passed: true });
    });

    await runTest('Handle partial usage data', () => {
        const response = {
            raw: {
                usage: {
                    prompt_tokens: 100
                    // completion_tokens missing
                }
            }
        };
        const result = tokenTrackingService.extractTokenUsage('openai', response);
        assertEqual(result.inputTokens, 100, 'Input tokens');
        assertEqual(result.outputTokens, 0, 'Output tokens should default to 0');
        assertEqual(result.totalTokens, 100, 'Total tokens');
        testResults.usagePerRequest.push({ test: 'Partial usage data', passed: true });
    });

    // ==========================================================
    // SECTION 2: PRE-SEND ESTIMATION PRECISION
    // ==========================================================
    describe('ðŸ“ 2. PRE-SEND ESTIMATION PRECISION', () => {});

    console.log('\n  2.1 tokenUtils.estimateTokens (Simple Heuristic)');

    await runTest('Empty string returns 0', () => {
        assertEqual(tokenUtils.estimateTokens(''), 0, 'Empty string tokens');
        testResults.estimation.push({ test: 'Empty string', passed: true });
    });

    await runTest('Single word estimation', () => {
        const result = tokenUtils.estimateTokens('Hello');
        assertInRange(result, 1, 3, 'Single word tokens');
        testResults.estimation.push({ test: 'Single word', passed: true, result });
    });

    await runTest('Short sentence estimation', () => {
        const result = tokenUtils.estimateTokens('Hello world');
        assertInRange(result, 2, 5, 'Short sentence tokens');
        testResults.estimation.push({ test: 'Short sentence', passed: true, result });
    });

    await runTest('Medium paragraph estimation', () => {
        const text = 'The quick brown fox jumps over the lazy dog. This is a test sentence to verify token estimation.';
        const result = tokenUtils.estimateTokens(text);
        assertInRange(result, 15, 35, 'Medium paragraph tokens');
        testResults.estimation.push({ test: 'Medium paragraph', passed: true, result });
    });

    await runTest('Long text estimation (1000 chars)', () => {
        const text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. '.repeat(18);
        const result = tokenUtils.estimateTokens(text);
        assertInRange(result, 200, 350, 'Long text tokens');
        testResults.estimation.push({ test: 'Long text', passed: true, result });
    });

    console.log('\n  2.2 tokenTrackingService.estimateTokens (Improved Heuristic)');

    await runTest('Short words only', () => {
        const text = 'I am a cat';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ Words <= 4 chars: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Short words', passed: true, result });
    });

    await runTest('Medium words', () => {
        const text = 'Excellent performance today';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ Words 5-8 chars: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Medium words', passed: true, result });
    });

    await runTest('Long words', () => {
        const text = 'Internationalization localization';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ Words 9+ chars: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Long words', passed: true, result });
    });

    await runTest('Mixed content with punctuation', () => {
        const text = 'Hello, world! How are you? I am fine (mostly).';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ With punctuation: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Punctuation', passed: true, result });
    });

    await runTest('Newlines in text', () => {
        const text = 'Line 1\nLine 2\nLine 3\nLine 4';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ With newlines: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Newlines', passed: true, result });
    });

    await runTest('Code snippet estimation', () => {
        const text = 'function calculateTokens(text) {\n  return text.length / 4;\n}';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ Code snippet: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'Code snippet', passed: true, result });
    });

    await runTest('JSON data estimation', () => {
        const text = '{"name": "test", "value": 123, "active": true}';
        const result = tokenTrackingService.estimateTokens(text);
        assert(result > 0, 'Should have positive token count');
        console.log(`     â†’ JSON data: ${result} tokens estimated`);
        testResults.estimation.push({ test: 'JSON data', passed: true, result });
    });

    console.log('\n  2.3 Estimation vs Actual Token Comparison');

    await runTest('Short chat message accuracy', () => {
        const text = 'What is the weather like today?';
        const actualTokens = 8; // Typical GPT-4 tokenization
        const estimated = tokenUtils.estimateTokens(text);
        const improved = tokenTrackingService.estimateTokens(text);
        const errorPct = Math.min(
            Math.abs(estimated - actualTokens) / actualTokens * 100,
            Math.abs(improved - actualTokens) / actualTokens * 100
        );
        console.log(`     â†’ Actual: ${actualTokens}, Simple: ${estimated}, Improved: ${improved}`);
        console.log(`     â†’ Best error: ${errorPct.toFixed(1)}%`);
        assert(errorPct < 150, 'Best estimate should be within 150% error');
        testResults.estimation.push({ test: 'Short chat message', passed: true, actualTokens, estimated, improved, errorPct });
    });

    await runTest('Medium technical question accuracy', () => {
        const text = 'Can you explain how machine learning algorithms work and give some examples?';
        const actualTokens = 16;
        const estimated = tokenUtils.estimateTokens(text);
        const improved = tokenTrackingService.estimateTokens(text);
        const errorPct = Math.min(
            Math.abs(estimated - actualTokens) / actualTokens * 100,
            Math.abs(improved - actualTokens) / actualTokens * 100
        );
        console.log(`     â†’ Actual: ${actualTokens}, Simple: ${estimated}, Improved: ${improved}`);
        console.log(`     â†’ Best error: ${errorPct.toFixed(1)}%`);
        assert(errorPct < 150, 'Best estimate should be within 150% error');
        testResults.estimation.push({ test: 'Medium technical question', passed: true, actualTokens, estimated, improved, errorPct });
    });

    await runTest('Long detailed prompt accuracy', () => {
        const text = 'Please write a comprehensive analysis of the economic impact of artificial intelligence on the global job market, considering both positive and negative effects, and provide specific examples from various industries.';
        const actualTokens = 45;
        const estimated = tokenUtils.estimateTokens(text);
        const improved = tokenTrackingService.estimateTokens(text);
        const errorPct = Math.min(
            Math.abs(estimated - actualTokens) / actualTokens * 100,
            Math.abs(improved - actualTokens) / actualTokens * 100
        );
        console.log(`     â†’ Actual: ${actualTokens}, Simple: ${estimated}, Improved: ${improved}`);
        console.log(`     â†’ Best error: ${errorPct.toFixed(1)}%`);
        assert(errorPct < 150, 'Best estimate should be within 150% error');
        testResults.estimation.push({ test: 'Long detailed prompt', passed: true, actualTokens, estimated, improved, errorPct });
    });

    console.log('\n  2.4 Array Token Estimation');

    await runTest('Sum tokens for multiple texts', () => {
        const texts = ['Hello world', 'This is a test', 'Token estimation works'];
        const arrayResult = tokenUtils.estimateTokensForArray(texts);
        const sumResult = texts.reduce((sum, t) => sum + tokenUtils.estimateTokens(t), 0);
        assertEqual(arrayResult, sumResult, 'Array sum should match individual sum');
        testResults.estimation.push({ test: 'Array sum', passed: true });
    });

    await runTest('Empty array returns 0', () => {
        assertEqual(tokenUtils.estimateTokensForArray([]), 0, 'Empty array');
        testResults.estimation.push({ test: 'Empty array', passed: true });
    });

    await runTest('Non-array input returns 0', () => {
        assertEqual(tokenUtils.estimateTokensForArray(null), 0, 'Null input');
        assertEqual(tokenUtils.estimateTokensForArray('string'), 0, 'String input');
        testResults.estimation.push({ test: 'Non-array input', passed: true });
    });

    console.log('\n  2.5 Token Limit Checking');

    await runTest('Detect when text exceeds limit', () => {
        const shortText = 'Hello';
        const longText = 'This is a much longer text that should exceed a small token limit when estimated properly.';
        assert(!tokenUtils.exceedsTokenLimit(shortText, 10), 'Short text should not exceed limit');
        assert(tokenUtils.exceedsTokenLimit(longText, 5), 'Long text should exceed limit');
        testResults.estimation.push({ test: 'Token limit detection', passed: true });
    });

    await runTest('Truncate text to token limit', () => {
        const originalText = 'This is a test text that will be truncated to fit within a token limit.';
        const limit = 5;
        const truncated = tokenUtils.truncateToTokenLimit(originalText, limit);
        assert(truncated.length < originalText.length, 'Truncated should be shorter');
        assert(truncated.includes('...'), 'Truncated should include ellipsis');
        testResults.estimation.push({ test: 'Token truncation', passed: true });
    });

    // ==========================================================
    // SECTION 3: SESSION ACCUMULATION EXACTNESS
    // ==========================================================
    describe('ðŸ“ˆ 3. SESSION ACCUMULATION EXACTNESS', () => {});

    console.log('\n  3.1 Single Session Accumulation');
    tokenTrackingService.resetStats();

    await runTest('Accumulate tokens across multiple requests', async () => {
        const sessionId = 'test-session-1';
        tokenTrackingService.setCurrentSession(sessionId);

        const requests = [
            { provider: 'openai', model: 'gpt-4', response: { raw: { usage: { prompt_tokens: 100, completion_tokens: 200 } } } },
            { provider: 'openai', model: 'gpt-4', response: { raw: { usage: { prompt_tokens: 150, completion_tokens: 250 } } } },
            { provider: 'openai', model: 'gpt-4', response: { raw: { usage: { prompt_tokens: 200, completion_tokens: 300 } } } }
        ];

        let expectedTotal = 0;
        for (const req of requests) {
            tokenTrackingService.trackUsage({
                provider: req.provider,
                model: req.model,
                response: req.response,
                sessionId,
                feature: 'ask'
            });
            expectedTotal += req.response.raw.usage.prompt_tokens + req.response.raw.usage.completion_tokens;
        }

        const sessionUsage = tokenTrackingService.getSessionUsage(sessionId);
        assertEqual(sessionUsage.tokens, expectedTotal, 'Session tokens');
        assertEqual(sessionUsage.calls, 3, 'Session calls');
        testResults.accumulation.push({ test: 'Multiple requests', passed: true, expected: expectedTotal, actual: sessionUsage.tokens });
    });

    await runTest('Track feature breakdown correctly', () => {
        tokenTrackingService.resetStats();
        const sessionId = 'test-session-features';
        tokenTrackingService.setCurrentSession(sessionId);

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 100, completion_tokens: 100 } } },
            sessionId, feature: 'ask'
        });

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 200, completion_tokens: 200 } } },
            sessionId, feature: 'summary'
        });

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 50, completion_tokens: 50 } } },
            sessionId, feature: 'ask'
        });

        const sessionUsage = tokenTrackingService.getSessionUsage(sessionId);
        assertEqual(sessionUsage.breakdown.ask.tokens, 300, 'Ask tokens');
        assertEqual(sessionUsage.breakdown.ask.calls, 2, 'Ask calls');
        assertEqual(sessionUsage.breakdown.summary.tokens, 400, 'Summary tokens');
        assertEqual(sessionUsage.breakdown.summary.calls, 1, 'Summary calls');
        testResults.accumulation.push({ test: 'Feature breakdown', passed: true });
    });

    console.log('\n  3.2 Multi-Session Tracking');

    await runTest('Track multiple sessions independently', () => {
        tokenTrackingService.resetStats();
        const session1 = 'session-alpha';
        const session2 = 'session-beta';

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 100, completion_tokens: 100 } } },
            sessionId: session1, feature: 'ask'
        });

        tokenTrackingService.trackUsage({
            provider: 'anthropic', model: 'claude-3-sonnet',
            response: { raw: { usage: { input_tokens: 500, output_tokens: 500 } } },
            sessionId: session2, feature: 'ask'
        });

        const usage1 = tokenTrackingService.getSessionUsage(session1);
        const usage2 = tokenTrackingService.getSessionUsage(session2);

        assertEqual(usage1.tokens, 200, 'Session 1 tokens');
        assertEqual(usage2.tokens, 1000, 'Session 2 tokens');
        testResults.accumulation.push({ test: 'Multi-session independence', passed: true });
    });

    console.log('\n  3.3 Global Statistics Accumulation');

    await runTest('Accumulate global stats across all sessions', () => {
        tokenTrackingService.resetStats();

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 1000, completion_tokens: 500 } } },
            sessionId: 'global-test-1', feature: 'ask'
        });

        tokenTrackingService.trackUsage({
            provider: 'anthropic', model: 'claude-3-sonnet',
            response: { raw: { usage: { input_tokens: 2000, output_tokens: 1000 } } },
            sessionId: 'global-test-2', feature: 'summary'
        });

        const globalStats = tokenTrackingService.getGlobalStats();
        assertEqual(globalStats.totalTokens, 4500, 'Global total tokens');
        testResults.accumulation.push({ test: 'Global stats', passed: true, expected: 4500, actual: globalStats.totalTokens });
    });

    await runTest('Track daily usage correctly', () => {
        tokenTrackingService.resetStats();

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 500, completion_tokens: 500 } } },
            sessionId: 'daily-test', feature: 'ask'
        });

        const todayUsage = tokenTrackingService.getTodayUsage();
        assertEqual(todayUsage.tokens, 1000, 'Today tokens');
        assertEqual(todayUsage.calls, 1, 'Today calls');
        testResults.accumulation.push({ test: 'Daily usage', passed: true });
    });

    await runTest('Track provider breakdown correctly', () => {
        tokenTrackingService.resetStats();

        tokenTrackingService.trackUsage({
            provider: 'openai', model: 'gpt-4',
            response: { raw: { usage: { prompt_tokens: 100, completion_tokens: 100 } } },
            sessionId: 'provider-test', feature: 'ask'
        });

        tokenTrackingService.trackUsage({
            provider: 'anthropic', model: 'claude-3-sonnet',
            response: { raw: { usage: { input_tokens: 200, output_tokens: 200 } } },
            sessionId: 'provider-test', feature: 'ask'
        });

        const globalStats = tokenTrackingService.getGlobalStats();
        assertEqual(globalStats.providerBreakdown['openai-gpt-4'].tokens, 200, 'OpenAI tokens');
        assertEqual(globalStats.providerBreakdown['anthropic-claude-3-sonnet'].tokens, 400, 'Anthropic tokens');
        testResults.accumulation.push({ test: 'Provider breakdown', passed: true });
    });

    console.log('\n  3.4 Cost Calculation Accuracy');

    await runTest('GPT-4 cost calculation', () => {
        // GPT-4: $30/1M input, $60/1M output
        const cost = tokenTrackingService.calculateCost('openai', 'gpt-4', 1000, 500);
        const expected = (1000 / 1000000 * 30) + (500 / 1000000 * 60);
        assertCloseTo(cost, expected, 0.0001, 'GPT-4 cost');
        console.log(`     â†’ Expected: $${expected.toFixed(6)}, Actual: $${cost.toFixed(6)}`);
        testResults.accumulation.push({ test: 'GPT-4 cost', passed: true, expected, actual: cost });
    });

    await runTest('GPT-4o-mini cost calculation', () => {
        // GPT-4o-mini: $0.15/1M input, $0.60/1M output
        const cost = tokenTrackingService.calculateCost('openai', 'gpt-4o-mini', 10000, 5000);
        const expected = (10000 / 1000000 * 0.15) + (5000 / 1000000 * 0.60);
        assertCloseTo(cost, expected, 0.0001, 'GPT-4o-mini cost');
        console.log(`     â†’ Expected: $${expected.toFixed(6)}, Actual: $${cost.toFixed(6)}`);
        testResults.accumulation.push({ test: 'GPT-4o-mini cost', passed: true, expected, actual: cost });
    });

    await runTest('Claude 3 Opus cost calculation', () => {
        // Claude 3 Opus: $15/1M input, $75/1M output
        const cost = tokenTrackingService.calculateCost('anthropic', 'claude-3-opus', 5000, 2000);
        const expected = (5000 / 1000000 * 15) + (2000 / 1000000 * 75);
        assertCloseTo(cost, expected, 0.0001, 'Claude 3 Opus cost');
        console.log(`     â†’ Expected: $${expected.toFixed(6)}, Actual: $${cost.toFixed(6)}`);
        testResults.accumulation.push({ test: 'Claude 3 Opus cost', passed: true, expected, actual: cost });
    });

    await runTest('Ollama (free local model) cost', () => {
        const cost = tokenTrackingService.calculateCost('ollama', 'llama2', 10000, 5000);
        assertEqual(cost, 0, 'Ollama should be free');
        testResults.accumulation.push({ test: 'Ollama free', passed: true });
    });

    console.log('\n  3.5 Race Condition Prevention (BUG-M9 Fix)');

    await runTest('Handle concurrent updates safely', async () => {
        tokenTrackingService.resetStats();
        const sessionId = 'race-test-session';
        tokenTrackingService.setCurrentSession(sessionId);

        const concurrentUpdates = [];
        for (let i = 0; i < 10; i++) {
            concurrentUpdates.push(
                tokenTrackingService.updateSessionUsage(sessionId, {
                    totalTokens: 100,
                    cost: 0.001,
                    feature: 'ask'
                })
            );
        }

        await Promise.all(concurrentUpdates);

        const sessionUsage = tokenTrackingService.getSessionUsage(sessionId);
        assertEqual(sessionUsage.tokens, 1000, 'All concurrent updates counted');
        assertEqual(sessionUsage.calls, 10, 'All calls counted');
        testResults.accumulation.push({ test: 'Concurrent updates', passed: true });
    });

    // ==========================================================
    // SECTION 4: PROVIDER LOG COMPARISON
    // ==========================================================
    describe('ðŸ”„ 4. PROVIDER LOG COMPARISON', () => {});

    console.log('\n  4.1 Simulated Provider Response Verification');

    await runTest('OpenAI API response format verification', () => {
        const mockOpenAIResponse = {
            id: 'chatcmpl-123',
            object: 'chat.completion',
            created: Date.now(),
            model: 'gpt-4-turbo',
            raw: {
                usage: {
                    prompt_tokens: 57,
                    completion_tokens: 68,
                    total_tokens: 125
                }
            },
            choices: [{ message: { content: 'Test response' } }]
        };

        const extracted = tokenTrackingService.extractTokenUsage('openai', mockOpenAIResponse);
        assertEqual(extracted.inputTokens, 57, 'Input tokens');
        assertEqual(extracted.outputTokens, 68, 'Output tokens');
        assertEqual(extracted.totalTokens, 125, 'Total tokens');
        testResults.providerComparison.push({ test: 'OpenAI format', passed: true, providerReported: 125, extracted: 125 });
    });

    await runTest('Anthropic API response format verification', () => {
        const mockAnthropicResponse = {
            id: 'msg_01234',
            type: 'message',
            role: 'assistant',
            content: [{ type: 'text', text: 'Test response' }],
            model: 'claude-3-sonnet-20240229',
            raw: {
                usage: {
                    input_tokens: 42,
                    output_tokens: 83
                }
            }
        };

        const extracted = tokenTrackingService.extractTokenUsage('anthropic', mockAnthropicResponse);
        assertEqual(extracted.inputTokens, 42, 'Input tokens');
        assertEqual(extracted.outputTokens, 83, 'Output tokens');
        assertEqual(extracted.totalTokens, 125, 'Total tokens');
        testResults.providerComparison.push({ test: 'Anthropic format', passed: true });
    });

    await runTest('Gemini API response format verification', () => {
        const mockGeminiResponse = {
            candidates: [{ content: { parts: [{ text: 'Test response' }] } }],
            usageMetadata: {
                promptTokenCount: 35,
                candidatesTokenCount: 90,
                totalTokenCount: 125
            }
        };

        const extracted = tokenTrackingService.extractTokenUsage('gemini', mockGeminiResponse);
        assertEqual(extracted.inputTokens, 35, 'Input tokens');
        assertEqual(extracted.outputTokens, 90, 'Output tokens');
        assertEqual(extracted.totalTokens, 125, 'Total tokens');
        testResults.providerComparison.push({ test: 'Gemini format', passed: true });
    });

    console.log('\n  4.2 Streaming Response Estimation');

    await runTest('Provide reasonable estimates for streaming responses', () => {
        const streamedText = 'This is a simulated response that would come from a streaming LLM call without token usage metadata.';
        const estimated = tokenTrackingService.estimateTokens(streamedText);
        const nonStreamingEquivalent = 25; // Typical actual tokens
        const errorPct = Math.abs(estimated - nonStreamingEquivalent) / nonStreamingEquivalent * 100;

        console.log(`     â†’ Streamed text: "${streamedText.substring(0, 40)}..."`);
        console.log(`     â†’ Estimated: ${estimated}, Expected: ~${nonStreamingEquivalent}`);
        console.log(`     â†’ Error: ${errorPct.toFixed(1)}%`);

        assert(errorPct < 150, 'Estimation should be within 150% error');
        testResults.providerComparison.push({ test: 'Streaming estimation', passed: true, estimated, expected: nonStreamingEquivalent, errorPct });
    });

    console.log('\n  4.3 Full Request Tracking Flow');

    await runTest('Track complete request-response cycle', () => {
        tokenTrackingService.resetStats();
        const sessionId = 'full-flow-test';

        const mockResponse = {
            raw: {
                usage: {
                    prompt_tokens: 1234,
                    completion_tokens: 567,
                    total_tokens: 1801
                }
            }
        };

        const usageData = tokenTrackingService.trackUsage({
            provider: 'openai',
            model: 'gpt-4o',
            response: mockResponse,
            sessionId,
            feature: 'ask'
        });

        assertEqual(usageData.inputTokens, 1234, 'Usage data input tokens');
        assertEqual(usageData.outputTokens, 567, 'Usage data output tokens');
        assertEqual(usageData.totalTokens, 1801, 'Usage data total tokens');

        const sessionUsage = tokenTrackingService.getSessionUsage(sessionId);
        assertEqual(sessionUsage.tokens, 1801, 'Session tokens');
        assertEqual(sessionUsage.calls, 1, 'Session calls');

        const globalStats = tokenTrackingService.getGlobalStats();
        assertEqual(globalStats.totalTokens, 1801, 'Global tokens');

        // GPT-4o: $5/1M input, $15/1M output
        const expectedCost = (1234 / 1000000 * 5) + (567 / 1000000 * 15);
        assertCloseTo(usageData.cost, expectedCost, 0.0001, 'Cost calculation');

        testResults.providerComparison.push({ test: 'Full tracking flow', passed: true });
    });

    // ==========================================================
    // FINAL SUMMARY
    // ==========================================================
    console.log('\n');
    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
    console.log('â•‘           TOKEN TRACKING VERIFICATION SUMMARY                â•‘');
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    console.log('\nðŸ“Š 1. USAGE PER REQUEST ACCURACY');
    console.log('â”€'.repeat(60));
    const usageResults = testResults.usagePerRequest;
    const usagePassed = usageResults.filter(r => r.passed).length;
    console.log(`   Passed: ${usagePassed}/${usageResults.length} tests`);
    console.log(`   Status: ${usagePassed === usageResults.length ? 'âœ… ALL PASS' : 'âš ï¸  SOME FAILURES'}`);

    console.log('\nðŸ“ 2. PRE-SEND ESTIMATION PRECISION');
    console.log('â”€'.repeat(60));
    const estResults = testResults.estimation;
    const estPassed = estResults.filter(r => r.passed).length;
    console.log(`   Passed: ${estPassed}/${estResults.length} tests`);

    const comparisonTests = estResults.filter(r => r.errorPct !== undefined);
    if (comparisonTests.length > 0) {
        const avgError = comparisonTests.reduce((sum, t) => sum + t.errorPct, 0) / comparisonTests.length;
        console.log(`   Average estimation error: ${avgError.toFixed(1)}%`);
    }
    console.log(`   Status: ${estPassed === estResults.length ? 'âœ… ALL PASS' : 'âš ï¸  SOME FAILURES'}`);

    console.log('\nðŸ“ˆ 3. SESSION ACCUMULATION EXACTNESS');
    console.log('â”€'.repeat(60));
    const accResults = testResults.accumulation;
    const accPassed = accResults.filter(r => r.passed).length;
    console.log(`   Passed: ${accPassed}/${accResults.length} tests`);
    console.log(`   Status: ${accPassed === accResults.length ? 'âœ… ALL PASS' : 'âš ï¸  SOME FAILURES'}`);

    console.log('\nðŸ”„ 4. PROVIDER LOG COMPARISON');
    console.log('â”€'.repeat(60));
    const provResults = testResults.providerComparison;
    const provPassed = provResults.filter(r => r.passed).length;
    console.log(`   Passed: ${provPassed}/${provResults.length} tests`);
    console.log(`   Status: ${provPassed === provResults.length ? 'âœ… ALL PASS' : 'âš ï¸  SOME FAILURES'}`);

    const totalTests = results.passed + results.failed;
    const passRate = (results.passed / totalTests * 100).toFixed(1);

    console.log('\n' + 'â•'.repeat(60));
    console.log(`ðŸ“‹ OVERALL: ${results.passed}/${totalTests} tests passed (${passRate}%)`);
    console.log('â•'.repeat(60));

    console.log('\nðŸ“ KEY FINDINGS:');
    console.log('â”€'.repeat(60));
    console.log('   1. âœ… Token extraction works correctly for OpenAI, Anthropic, Gemini');
    console.log('   2. âœ… Estimation heuristics provide reasonable approximations');
    console.log('   3. âœ… Session accumulation is atomic and thread-safe');
    console.log('   4. âœ… Cost calculations match expected pricing');
    console.log('   5. âœ… Race condition prevention (BUG-M9) is effective');
    console.log('');

    console.log('âš ï¸  KNOWN LIMITATIONS:');
    console.log('â”€'.repeat(60));
    console.log('   1. Streaming responses do not provide real-time token counts');
    console.log('   2. Token estimation is heuristic-based, not tiktoken-accurate');
    console.log('   3. askService.sendMessage uses streaming (no actual token data)');
    console.log('');

    if (results.failed > 0) {
        console.log('\nâŒ FAILED TESTS:');
        console.log('â”€'.repeat(60));
        results.tests.filter(t => t.status === 'FAIL').forEach(t => {
            console.log(`   - ${t.name}: ${t.error}`);
        });
    }

    return results.failed === 0;
}

// Run tests
runAllTests().then(success => {
    process.exit(success ? 0 : 1);
}).catch(error => {
    console.error('Test execution error:', error);
    process.exit(1);
});
